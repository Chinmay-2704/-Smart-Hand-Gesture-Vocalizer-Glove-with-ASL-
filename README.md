# -Smart-Hand-Gesture-Vocalizer-Glove-with-ASL-

A wearable **Smart Glove** designed to translate **American Sign Language (ASL)** gestures into text and speech in real-time.  
This project leverages **flex sensors, MPU6050 motion sensor, and touch sensors** integrated with **Arduino Nano** and **Bluetooth communication** to provide an affordable assistive tool for the speech and hearing-impaired community.  

---

## ğŸš€ Features
- **Dual-Mode Operation**  
  - **ASL Mode:** Recognizes individual alphabets of American Sign Language to form words.  
  - **Predefined Gesture Mode:** Maps specific gestures to essential phrases (e.g., "Food", "Medicine", "Help").  

- **Real-Time Wireless Output**  
  - Uses **HC-05 Bluetooth module** to send translated gestures to smartphones/PCs.  
  - Displays output as **text or speech** via paired applications.  

- **Compact & Affordable Design**  
  - Custom PCB for efficient wiring and durability.  
  - Lightweight **3D-printed enclosure** for portability and comfort.  
  - Built under â‚¹3000, making it cost-effective compared to commercial alternatives.  

---

## ğŸ› ï¸ Components Used
- Arduino Nano  
- Flex Sensors (5 units)  
- MPU6050 (Gyroscope + Accelerometer)  
- Touch Sensors (Silver Tape-based)  
- HC-05 Bluetooth Module  
- 9V Lithium Battery  
- Custom PCB + 3D Printed Enclosure  

---

## âš™ï¸ Working Principle
1. Flex, motion, and touch sensors detect finger bends, hand orientation, and finger contacts.  
2. Arduino Nano processes sensor data using threshold-based logic.  
3. Interpreted gestures are transmitted wirelessly to paired devices.  
4. Output is displayed as **text or converted to speech** for real-time communication.  

---

## ğŸ“Š Applications
- **Assistive Technology** â€“ Helps speech and hearing-impaired individuals communicate effectively.  
- **Education** â€“ Learning and teaching ASL in schools and institutions.  
- **Emergency Use** â€“ Quick gestures mapped to essential commands (e.g., â€œEmergencyâ€, â€œNeed Helpâ€).  
- **Future Scope** â€“ Can be extended with **AI/ML for dynamic gesture recognition**, support for multiple sign languages, and mobile/cloud integration.  

---

## ğŸ–¼ï¸ Block Diagram
<img width="1282" height="673" alt="image" src="https://github.com/user-attachments/assets/05247b87-ae8b-43aa-8959-17e87e1c521e" />
 

---

## ğŸ“¸ Prototype
![Prototype](https://github.com/user-attachments/assets/a73dfeda-7144-4c43-9274-aaad78845c21)
 

---

